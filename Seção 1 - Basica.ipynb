{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seção 1 -  Comandos básicos\n",
    "\n",
    "Nessa primeira parte iremos ver alguns comandos básicos da biblioteca OpenCV\n",
    "\n",
    "1. Leitura da imagem\n",
    "2. Capturar vídeo\n",
    "3. Redimensionar Imagens\n",
    "4. Desenhar Figuras básicas e Inserir textos\n",
    "5. Transformações básicas nas imagens\n",
    "6. Detecção de Contornos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura da imagem\n",
    "\n",
    "O método **cv2.imread()** carrega uma imagem do arquivo especificado. Se a imagem não pode ser lida (por causa de arquivo ausente, permissões impróprias, formato não suportado ou inválido), este método retorna uma matriz vazia.\n",
    "\n",
    "**Sintaxe**: cv2.imread (caminho, flag)\n",
    "\n",
    "**Parâmetros**:\n",
    "caminho: uma string que representa o caminho da imagem a ser lida.\n",
    "flag: especifica a forma como a imagem deve ser lida. Seu valor padrão é cv2.IMREAD_COLOR\n",
    "\n",
    "    cv2.IMREAD_COLOR: Especifica o carregamento de uma imagem colorida. Qualquer transparência da imagem será desprezada. É o flag padrão. Como alternativa, podemos passar o valor inteiro 1 para este sinalizador.\n",
    "    cv2.IMREAD_GRAYSCALE: Especifica o carregamento de uma imagem em modo de escala de cinza. Como alternativa, podemos passar o valor inteiro 0 para este sinalizador.\n",
    "    cv2.IMREAD_UNCHANGED: Especifica o carregamento de uma imagem como tal, incluindo o canal alfa. Alternativamente, podemos passar o valor inteiro -1 para este sinalizador.\n",
    "\n",
    "Valor de retorno: este método retorna uma imagem que é carregada do arquivo especificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('foto_sol.jpg')\n",
    "cv2.imshow(\"Imagem Exemplo\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Capturar vídeo da câmera\n",
    "\n",
    "\n",
    "Freqüentemente, temos que capturar a transmissão ao vivo com a câmera. O OpenCV fornece uma interface muito simples para isso. Vamos capturar um vídeo da câmera (estou usando a webcam embutida do meu laptop).\n",
    "\n",
    "Para capturar um vídeo, você precisa criar um objeto **VideoCapture**. Seu argumento pode ser o índice do dispositivo ou o nome de um arquivo de vídeo. O índice do dispositivo é apenas o número para especificar qual câmera. Normalmente, uma câmera será conectada (como no meu caso). Então, simplesmente passo 0 (ou -1). Você pode selecionar a segunda câmera passando 1 e assim por diante. Depois disso, você pode capturar quadro a quadro. Mas no final, não se esqueça de liberar a captura.\n",
    "\n",
    "\n",
    "**capture.read()** retorna um bool (True / False). Se o quadro for lido corretamente, será True. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture('video_exemplo.mp4')\n",
    "\n",
    "while True:\n",
    "    isTrue, frame = capture.read()\n",
    "    \n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    if cv2.waitKey(20) & 0xFF==ord('q'):\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redimensionar imagem\n",
    "\n",
    "Redimensionar uma imagem significa alterar suas dimensões, seja apenas largura, altura ou ambos. Além disso, a proporção da imagem original pode ser preservada na imagem redimensionada. Para redimensionar uma imagem, OpenCV fornece a função **cv2.resize()**.\n",
    "\n",
    "**Sintaxe**: cv2.resize(src, dsize[, dst[, fx[, fy[, interpolation]]]])\n",
    "\n",
    "**Parâmetros**:\n",
    "src: imagem de entrada\n",
    "dsize: tamanho desejado para a imagem de daisa \n",
    "fx: Fator de escala ao longo do eixo X\n",
    "fy: Fator de escala ao longo do eixo y\n",
    "interpolation:\n",
    "\n",
    "    * INTER_NEAREST - uma interpolação do vizinho mais próximo \n",
    "    * INTER_LINEAR - uma interpolação bilinear (usada por padrão) \n",
    "    * INTER_AREA - reamostragem usando a relação de área de pixel. Pode ser um método preferido para dizimação de imagem, pois fornece resultados sem moiré. Mas quando a imagem é ampliada, é semelhante ao método INTER_NEAREST. \n",
    "    * INTER_CUBIC - uma interpolação bicúbica na vizinhança de 4 × 4 pixels \n",
    "    * INTER_LANCZOS4 - uma interpolação Lanczos na vizinhança de 8 × 8 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeira função\n",
    "def rescaleFrame(frame, scale=0.75):\n",
    "    # Aplicacao: Imagens, Videos e Lives Videos\n",
    "    width = int(frame.shape[1] * scale)\n",
    "    heigth = int(frame.shape[0] * scale)\n",
    "    \n",
    "    dimensions = (width, heigth)\n",
    "    \n",
    "    return cv2.resize(frame, dimensions, interpolation = cv2.INTER_AREA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture('video_exemplo.mp4')\n",
    "\n",
    "while True:\n",
    "    isTrue, frame = capture.read()\n",
    "    frame_resize = rescaleFrame(frame, scale=0.25)\n",
    "    \n",
    "    cv2.imshow('Video', frame_resize)\n",
    "\n",
    "    if cv2.waitKey(20) & 0xFF==ord('q'):\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desenhar figura e colocar Texto\n",
    "\n",
    "Rentângulo\n",
    "\n",
    "**Sintaxe**: cv2.rectangle (imagem, ponto_inicial, ponto_final, cor, espessura)\n",
    "\n",
    "     Parâmetros:\n",
    "     * imagem: É a imagem na qual o retângulo deve ser desenhado.\n",
    "     * ponto_inicial: São as coordenadas iniciais do retângulo. As coordenadas são representadas como tuplas de dois valores, ou seja, (valor da coordenada X, valor da coordenada Y).\n",
    "     * ponto_final: São as coordenadas finais do retângulo. As coordenadas são representadas como tuplas de dois valores, ou seja, (valor da coordenada X, valor da coordenada Y).\n",
    "     * cor: é a cor da linha de borda do retângulo a ser desenhada. Para BGR, passamos uma tupla. por exemplo: (255, 0, 0) para a cor azul.\n",
    "     * espessura: É a espessura da linha da borda do retângulo em px. Espessura de -1 px preencherá a forma do retângulo com a cor especificada.\n",
    "\n",
    "     Valor de retorno: imagem.\n",
    "     \n",
    "**Sintaxe**: cv2.circle (imagem, coordenadas_centrais, raio, cor, espessura)\n",
    "\n",
    "    Parâmetros:\n",
    "    * imagem: É a imagem na qual o círculo será desenhado.\n",
    "    * coordenadas_centrais: São as coordenadas do centro do círculo. As coordenadas são representadas como tuplas de dois valores, ou seja, (valor da coordenada X, valor da coordenada Y).\n",
    "    * raio: é o raio do círculo.\n",
    "    * cor: é a cor da linha limite do círculo a ser desenhada. Para BGR, passamos uma tupla. por exemplo: (255, 0, 0) para a cor azul.\n",
    "    * espessura: É a espessura da linha da borda do círculo em px. Espessura de -1 px preencherá a forma do círculo com a cor especificada.\n",
    "    * Valor de retorno:imagem.\n",
    "    \n",
    "    \n",
    "**sintaxe**: cv2.line (imagem, ponto_inicial, ponto_final, cor, espessura)\n",
    "\n",
    "    Parâmetros:\n",
    "    * imagem: é a imagem na qual a linha deve ser desenhada.\n",
    "    * ponto_inicial: São as coordenadas iniciais da linha. As coordenadas são representadas como tuplas de dois valores, ou seja, (valor da coordenada X, valor da coordenada Y).\n",
    "    * ponto_final: São as coordenadas finais da linha. As coordenadas são representadas como tuplas de dois valores, ou seja, (valor da coordenada X, valor da coordenada Y).\n",
    "    * cor: é a cor da linha a ser desenhada. Para BGR, passamos uma tupla. por exemplo: (255, 0, 0) para a cor azul.\n",
    "    * espessura: é a espessura da linha em px.\n",
    "\n",
    "    Valor de retorno: ele retorna uma imagem.\n",
    "\n",
    "**Sintaxe**: cv2.putText (imagem, texto, org, fonte, fontScale, cor [, espessura [, lineType [, bottomLeftOrigin]]])\n",
    "\n",
    "    Parâmetros:\n",
    "    * imagem: é a imagem na qual o texto será desenhado.\n",
    "    * texto: string de texto a ser desenhada.\n",
    "    * org: São as coordenadas do canto inferior esquerdo da string de texto na imagem. As coordenadas são representadas como tuplas de dois valores, ou seja, (valor da coordenada X, valor da coordenada Y).\n",
    "    * fonte: denota o tipo de fonte. Alguns tipos de fonte são **FONT_HERSHEY_SIMPLEX**, **FONT_HERSHEY_PLAIN**, etc.\n",
    "    * fontScale: Fator de escala da fonte que é multiplicado pelo tamanho base específico da fonte.\n",
    "    * color: é a cor da string de texto a ser desenhada. Para BGR, passamos uma tupla. por exemplo: (255, 0, 0) para a cor azul.\n",
    "    * espessura: é a espessura da linha em px.\n",
    "    * lineType: Este é um parâmetro opcional. Fornece o tipo da linha a ser usada.\n",
    "    * bottomLeftOrigin: este é um parâmetro opcional. Quando for verdade, a origem dos dados da imagem está no canto inferior esquerdo. Caso contrário, está no canto superior esquerdo.\n",
    "\n",
    "    Valor de retorno: imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "blank = np.zeros((500,500,3), dtype='uint8')\n",
    "\n",
    "# 1. Pintar a imagem\n",
    "blank[200:300, 300:400] = 0,0,255\n",
    "cv2.imshow('Green', blank)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# 2. Desenhar um retangulo\n",
    "cv2.rectangle(blank, (0,0), (blank.shape[1]//2, blank.shape[0]//2), (0,255,0), thickness=-1)\n",
    "cv2.imshow('Rectangle', blank)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# 3. Desenhar um circulo\n",
    "cv2.circle(blank, (blank.shape[1]//2, blank.shape[0]//2), 40, (0,0,255), thickness=-1)\n",
    "cv2.imshow('Circle', blank)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# 4. Desenhar uma linha\n",
    "cv2.line(blank, (100,250), (300,400), (255,255,255), thickness=3)\n",
    "cv2.imshow('Line', blank)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# 5. Escrever um texto\n",
    "cv2.putText(blank, 'VII Semana da Engenharia!!', (0,225), cv2.FONT_HERSHEY_TRIPLEX, 1.0, (0,255,0), 2)\n",
    "cv2.imshow('Text', blank)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformações básicas na imagem\n",
    "\n",
    "\n",
    "A Translação é a mudança de localização do objeto. Se você conhece a mudança na direção (x, y), que seja (t_x, t_y), você pode criar a matriz de transformação $\\textbf{M}$ da seguinte maneira:\n",
    "\n",
    "\n",
    "$$M = \\begin{bmatrix} 1&0&t_x\\\\0&1&t_y\\end{bmatrix}$$\n",
    "\n",
    "Você pode transformá-lo em um array Numpy do tipo **np.float32** e passá-lo para a função **cv2.warpAffine()**. \n",
    "\n",
    "**Sintaxe**: cv2.warpAffine(src, M, dsize[, dst[, flags[, borderMode[, borderValue]]]] )\n",
    "\n",
    "     Parâmetros:\n",
    "     src: imagem de entrada.\n",
    "     dst: imagem de saída que tem o tamanho dsize e o mesmo tipo que src.\n",
    "     M: matriz de transformação.\n",
    "     dsize: tamanho da imagem de saída.\n",
    "     flags: combinação de métodos de interpolação\n",
    "     WARP_INVERSE_MAP que significa que M é a transformação inversa (dst-> src).\n",
    "     borderMode: método de extrapolação de pixel; quando borderMode = BORDER_TRANSPARENT, significa que os pixels na imagem de destino correspondentes aos “outliers” na imagem de origem não são modificados pela função.\n",
    "     borderValue: valor usado no caso de uma borda constante; por padrão, é 0.\n",
    "     \n",
    "**Sintaxe**: cv2.getRotationMatrix2D(center, angle, scale)\n",
    "\n",
    "     Parâmetros:\n",
    "     center: Centro da rotação da imagem.\n",
    "     angle: Graus para rotação da imagem\n",
    "     scale: Escala para rotação\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('foto_sol.jpg')\n",
    "cv2.imshow('Park', img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "# Translation\n",
    "def translate(img, x, y):\n",
    "    transMat = np.float32([[1,0,x],[0,1,y]])\n",
    "    dimensions = (img.shape[1], img.shape[0])\n",
    "    return cv2.warpAffine(img, transMat, dimensions)\n",
    "\n",
    "# -x --> Left\n",
    "# -y --> Up\n",
    "# x --> Right\n",
    "# y --> Down\n",
    "\n",
    "translated = translate(img, -100, 100)\n",
    "cv2.imshow('Translated', translated)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "# Rotacao\n",
    "def rotate(img, angle, rotPoint=None):\n",
    "    (height,width) = img.shape[:2]\n",
    "\n",
    "    if rotPoint is None:\n",
    "        rotPoint = (width//2,height//2)\n",
    "    \n",
    "    rotMat = cv2.getRotationMatrix2D(rotPoint, angle, 1.0)\n",
    "    dimensions = (width,height)\n",
    "\n",
    "    return cv2.warpAffine(img, rotMat, dimensions)\n",
    "\n",
    "rotated = rotate(img, -45)\n",
    "cv2.imshow('Rotated', rotated)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "rotated_rotated = rotate(img, -90)\n",
    "cv2.imshow('Rotated Rotated', rotated_rotated)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Flipping\n",
    "flip = cv.flip(img, -1)\n",
    "cv2.imshow('Flip', flip)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "# Cropping\n",
    "cropped = img[200:400, 300:400]\n",
    "cv2.imshow('Cropped', cropped)\n",
    "cv2.waitKey(0)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contornos\n",
    "\n",
    "https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_canny/py_canny.html\n",
    "\n",
    "#### O que é detecção de borda?\n",
    "\n",
    "A detecção de bordas é uma técnica de processamento de imagem para localizar os limites dos objetos dentro das imagens. Ele funciona detectando descontinuidades no brilho.\n",
    "\n",
    "#### Onde a detecção de borda é usada?\n",
    "\n",
    "A detecção de bordas é usada para segmentação de imagens e extração de dados em áreas como processamento de imagens, visão computacional.\n",
    "\n",
    "#### Teoria\n",
    "\n",
    "Canny Edge Detection é um algoritmo de detecção de bordas popular. Ele foi desenvolvido por John F. Canny em 1986. É um algoritmo de vários estágios e passaremos por cada um deles.\n",
    "\n",
    "    Estágios:\n",
    "    \n",
    "        * Redução de ruídos\n",
    "        * Gradientes de intensidade da imagem\n",
    "        * Supressão Non-Maximum\n",
    "        * Limiar de Histerese\n",
    "        \n",
    "\n",
    "#### Redução de ruído\n",
    "\n",
    "Como a detecção de bordas é suscetível a ruído na imagem, o primeiro passo é remover o ruído da imagem, usando por exemplo um filtro gaussiano 5x5.\n",
    "\n",
    "#### Encontrando o Gradiente de Intensidade da Imagem\n",
    "\n",
    "A imagem suavizada é então filtrada com um kernel Sobel nas direções horizontal e vertical para obter a primeira derivada na direção horizontal $(G_x)$ e na direção vertical $(G_y)$. A partir dessas duas imagens, podemos encontrar o gradiente de borda e a direção de cada pixel da seguinte maneira:\n",
    "\n",
    "$$Edge\\_Gradient\\;(G)=\\sqrt{G_x ^ 2 + G_y ^ 2}$$ \n",
    "$$Angle\\;(\\theta) = \\tan^{- 1}\\bigg(\\frac{G_y} {G_x}\\bigg)$$\n",
    "\n",
    "A direção do gradiente é sempre perpendicular às arestas. É arredondado em um dos quatro ângulos que representam as direções vertical, horizontal e duas diagonais.\n",
    "\n",
    "#### Supressão Non-Maximum\n",
    "\n",
    "Depois de obter a magnitude e a direção do gradiente, uma varredura completa da imagem é feita para remover quaisquer pixels indesejados que possam não constituir a borda. Para isso, a cada pixel, o pixel é verificado se é um máximo local em sua vizinhança na direção do gradiente. Confira a imagem abaixo:\n",
    "\n",
    "![Supressão Non-Maximum](nms.jpg)\n",
    "\n",
    "\n",
    "O ponto A está na borda (na direção vertical). A direção do gradiente é normal para a borda. Os pontos B e C estão em direções gradientes. Portanto, o ponto A é verificado com os pontos B e C para ver se ele forma um máximo local. Em caso afirmativo, é considerado para o próximo estágio, caso contrário, é suprimido (colocado em zero).\n",
    "\n",
    "Resumindo, o resultado que você obtém é uma imagem binária com “bordas finas”.\n",
    "\n",
    "#### Limiar de Histerese\n",
    "\n",
    "Este estágio decide quais arestas são realmente arestas e quais não são. Para isso, precisamos de dois valores de limite, **minVal** e **maxVal**. Quaisquer arestas com gradiente de intensidade maior que maxVal certamente são arestas e aquelas abaixo de minVal certamente não são arestas, portanto, descartadas. Aqueles que se encontram entre esses dois limites são classificados como bordas ou não com base em sua conectividade. Se eles estiverem conectados a pixels de “arestas seguras”, eles serão considerados parte das arestas. Caso contrário, eles também são descartados. Veja a imagem abaixo:\n",
    "\n",
    "![Histerese](hysteresis.jpg)\n",
    "\n",
    "A aresta A está acima de maxVal, portanto considerada “aresta segura”. Embora a aresta C esteja abaixo de maxVal, ela está conectada à aresta A, de modo que também é considerada uma aresta válida e obtemos essa curva completa. Mas a aresta B, embora esteja acima de minVal e esteja na mesma região da aresta C, ela não está conectada a nenhuma “aresta segura”, de modo que é descartada. Portanto, é muito importante selecionar minVal e maxVal de acordo para obter o resultado correto.\n",
    "\n",
    "Este estágio também remove pequenos ruídos de pixels na suposição de que as bordas são linhas longas.\n",
    "\n",
    "Então, o que finalmente conseguimos são bordas fortes na imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Gray', gray)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redução de ruído"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blur = cv2.GaussianBlur(gray, (5,5), cv2.BORDER_DEFAULT)\n",
    "cv2.imshow('Blur', blur)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canny = cv2.Canny(blur, 0, 90)\n",
    "cv2.imshow('Canny Edges', canny)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
